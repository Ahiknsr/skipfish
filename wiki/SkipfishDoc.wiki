#summary Project documentation
#labels Featured

=skipfish - web application security scanner=

  * Written and maintained by [http://lcamtuf.coredump.cx/ Michal Zalewski] <[mailto:lcamtuf@google.com lcamtuf@google.com]>. 
  * Copyright 2009 Google Inc, rights reserved.
  * Released under terms and conditions of the Apache License, version 2.0.

==What is skipfish?==

_Skipfish_ is an active web application security reconnaissance tool. The tool prepares an interactive view of the targeted site, based on the outcome of a traditional recursive crawl and dictionary-based probes. The report is additionally annotated with the outcomes of a number of (hopefully) non-disruptive security checks. The resulting report is meant to serve as a foundation for web application security assessments.

Although a number of commercial and open source tools with similar functionality is readily available, _skipfish_ specifically tries to address some of the common deficiencies in these applications. Specific advantages include:

  * *High performance:* 500+ requests per second against responsive Internet targets (10 simultaneous connections), 2000+ requests per second on LAN / MAN networks (4 connections), and 7000+ requests against local instances (2 connections) is not uncommon, all with a very modest CPU and memory footprint. Here's why:<p>
    * The tool features a multiplexing single-process, single-thread, fully asynchronous network I/O and data processing, eliminating massive memory management, scheduling, and IPC inefficiencies present in many multi-threaded clients.
    * It uses advanced HTTP/1.1 features such as range requests, content compression, and keep-alives, as well as forced response size limiting, to keep network-level overhead in check.
    * All check logic is designed to minimize waste: smart response caching and frequent behavior checks are used to avoid all unnecessary traffic.
    * Almost every component - including the custom HTTP stack - is written in pure C, with performance in mind. 

  * *Ease of use:* _skipfish_ is highly adaptive and reliable. The scanner features mechanisms such as:<p>
    * Automatic recognition of most path- and query-based parameter semantics, including aspects such as case sensitivity.
    * Graceful handling of multi-framework sites where certain paths obey a completely different logic, or may be bunged or filtered out unexpectedly.
    * Automatic wordlist builder based on site content analysis, promoting good picks to a persistent dictionary.
    * Probabilistic scanning features that allow periodic, time-bound assessments of arbitrarily complex sites.

  * *Cutting-edge security checks:*  the tool is to provide unique security insights without annoying the user:<p>
    * Most active checks are designed to avoid false positives by doing differential, three-way probes: baseline, a probe that if a vulnerability is predicted correctly should succeed, and a probe that should in such a case reliably fail.
    * [http://code.google.com/p/ratproxy Ratproxy] logic is used to spot a number of subtle security problems around cross-site request forgery, cross-site script inclusion, mixed content, MIME- and charset mismatches, caching issues, etc.
    * Provided security checks are capable of spotting challenging scenarios, such as stored XSS (path, parameters, headers), blind SQL or XML injection, or blind shell injection.
    * Report post-processing drastically reduces the noise caused by any remaining false positives or server gimmicks by identifying repetitive patterns. 

==Is it worth trying out?==

==What specific tests are implemented?==

==How to interpret and address the issues reported?==

==How to run the scanner?==

==Too long, didn't read...==

==Known limitations / feature wishlist==

==Credits, contributions, suggestions==